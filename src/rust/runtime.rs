//! The Rust runtime for Menhir
//!
//! All the parsers generated by [Menhir] with the `--rust` option (or using
//! the [`menhir`] package from crates.io) use functions and types from this
//! crate.
//!
//! This documentation is a reference API of the runtime library. It might be
//! useful to learn how to interact with the genarated parser from Rust code.
//! To learn how to write grammars, see the [Menhir manual]. To learn how to use
//! the generator to produce an executable Rust parser, see
//! [the documentation of the `menhir` crate].
//!
//! [Menhir]: http://gallium.inria.fr/~fpottier/menhir/
//! [`menhir`]: https://crates.io/crates/menhir
//! [Menhir manual]: http://gallium.inria.fr/~fpottier/menhir/manual.pdf
//!
//! # The runtime API
//!
//! The runtime library in this crate implements a classic LR(1) automaton loop
//! to interpret the parse tables generated from a grammar specification. This
//! implementation is highly generic in order to hide implementation details in
//! the generated code. The most notable elements are:
//!
//! * [`Lexer`], the lexer interface ; see also [`IteratorLexer`].
//! * [`LRParser`], the trait implemented by the generated parser, that exposes
//!   functions to access the generated parse table.
//!
//! [`Lexer`]: trait.Lexer.html
//! [`IteratorLexer`]: struct.IteratorLexer.html
//! [`LRParser`]: trait.LRParser.html
//!
//! # The lexer interface
//!
//! Menhir parsers do not require a specially-recognized EOF token. The user is
//! free to declare such a token in its specification but there is nothing
//! special about it: Menhir parsers are able to automatically detect when they
//! successfuly parsed recognized a start non-terminal without comsuming any
//! extra lookahead token. This way, what remains of the input can be used with
//! another invokation of the parser, or anything else.
//!
//! To represent this fact, the runtime uses its own [`Lexer`] trait, which
//! encodes an infinite stream of pairs of a token and its location.
//!
//! ```rust
//! trait Lexer {
//!     type Location;
//!     type Token;
//!     type Error;
//!
//!     fn input(&mut self) -> Result<(Self::Location, Self::Token),
//!                                   Self::Error>;
//! }
//! ```

use self::internals::*;
use self::lexing::*;

/// The internal representation of the LR engine.
///
/// Types and functions exposed in this module have to pe public because they
/// are used from the generated code but should not be considered stable for the
/// moment.
pub mod internals {
    pub type Stack<YYType, State> = Vec<(State, YYType)>;

    // The type of semantic actions.
    // Some(ptr) = a flat (not closure) code pointer to the handler
    // None = this is a start reduction. it's actually never executed but
    // indicates an Accept action instead. Since NULL is not a valid function
    // pointer in correct Rust code, this should be optimized to be just the size
    // of a function pointer.
    pub type SemAct<YYType, State> = Option<fn(State, &mut Stack<YYType, State>)
                                               -> State>;

    // An action, i.e. an entry in the action table. Error, accept, reduce with a
    // semantic function that takes the stack, modifie it and returns the next state
    // or shift to state, discarding the current token.
    pub enum Action<YYType, State> {
        Err,
        Reduce(SemAct<YYType, State>),
        Shift(State)
    }

    impl<T, U: Copy> Copy for Action<T, U> {}

    impl<T, U: Clone> Clone for Action<T, U> {
        fn clone(&self) -> Self {
            match *self {
                Action::Err => Action::Err,
                Action::Reduce(act) => Action::Reduce(act),
                Action::Shift(ref shift) => Action::Shift(shift.clone())
            }
        }
    }
}

/// The lexer interface.
pub mod lexing {
    /// The lexer interface.
    ///
    /// This trait describes the interface that a Menhir parser expects from the
    /// lexer. It can be seen as an infinite iterator over tokens and locations,
    /// that can also report errors.
    ///
    /// Several lexer generators or lexing tools expose a simpler interface based
    /// on the [`Iterator`] trait. They can be easily converted to this interface
    /// using [`IteratorLexer`].
    /// 
    /// [`Iterator`]: https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html
    /// [`IteratorLexer`]: struct.IteratorLexer.html
    ///
    /// The stream of tokens
    pub trait Lexer {
        /// A type that describes the position of a token in the input source,
        /// for example a line and column number.
        ///
        /// The actual value of this type is left purely at the discretion of the
        /// user. Menhir does not make any assumption on it and simply carries it
        /// through the parsing process to report it when an error occurs. The
        /// user can use any type appropriate for their error reporting
        /// mechanism, or even `()` if tracking of locations is not desired.
        type Location;

        /// The type of tokens returned by this lexer.
        type Token;

        /// A type that describes the possible errors that the lexer might
        /// encounter while processing the input source.
        ///
        /// As with `Location`, Menhir does not make any assumption on this type
        /// and simply returns it unaltered when the lexer returns it. The user
        /// can use any type appropriate for their error reporting mechanism, or
        /// even `()` if if this lexer cannot fail.
        type Error;

        /// Reads the next token from the input.
        ///
        /// On success, returns a pair of the token and its location in the input
        /// source. On failure, returns a value describing the error. Returning
        /// an error from the lexer will cause a Menhir parser to stop the
        /// parsing process and report it.
        ///
        /// Menhir parsers are able to detect successful termination without
        /// requiring extra lookahead. Because of this, no special value is
        /// required to indicate the end of the stream. If the end of the stream
        /// is encountered, `input` should report an error. This behaviour allows
        /// the parser not to consume any token it does not need and leave the
        /// lexer intact to be used for another parsing process. If one does want
        /// the parser to use exactly the whole input, one should either
        /// implement explicitly an “EOF” token in the grammar, or simply
        /// manually check that the lexer has no more tokens to offer once
        /// parsing succeeded.
        fn input(&mut self) -> Result<(Self::Location, Self::Token), Self::Error>;
    }

    /// Adapter type to convert an iterator into a lexer.
    ///
    /// Lexing tools that implement an interface based on [`Iterator`] can be
    /// converted to Menhir's more advanced [`Lexer`] interface by using this
    /// type.
    ///
    /// If the iterator returns `None` while the parser still needs tokens,
    /// `input` will return an [`UnexpectedEof`] error. If one wants the parser
    /// to consume exactly all the tokens, one should manually check that the
    /// underlying iterator is empty once parsing succeeded.
    ///
    /// [`Iterator`]: https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html
    /// [`Lexer`]: trait.Lexer.html
    /// [`UnexpectedEof`]: struct.UnexpectedEof.html
    pub struct IteratorLexer<Iter, Loc, Tok>
        where Iter: Iterator<Item = (Loc, Tok)> {
        iter: Iter,
        last_pos: Loc,
        marker: ::std::marker::PhantomData<(Loc, Tok)>
    }

    /// This error indicates that the lexer reached the end of the input stream
    /// while the parser was still expecting input.
    ///
    /// It is used when using an [`IteratorLexer`] as input, if the underlying
    /// iterator returns `None`. It can also be used to report the end of the
    /// stream when implementing a custom [`Lexer`].
    ///
    /// [`IteratorLexer`]: struct.IteratorLexer.html
    /// [`Lexer`]: trait.Lexer.html
    #[derive(Clone, Copy, Debug)]
    pub struct UnexpectedEof<Location>(pub Location);

    impl<Iter, Loc, Tok> Lexer for IteratorLexer<Iter, Loc, Tok>
        where Loc: Clone, Iter: Iterator<Item = (Loc, Tok)> {
        type Location = Loc;
        type Token = Tok;
        type Error = UnexpectedEof<Self::Location>;

        fn input(&mut self) -> Result<(Loc, Tok), Self::Error> {
            match self.iter.next() {
                Some((pos, tok)) => {
                    self.last_pos = pos.clone();
                    Ok((pos, tok))
                }
                None => Err(UnexpectedEof(self.last_pos.clone()))
            }
        }
    }

    impl<Iter, Loc, Tok> IteratorLexer<Iter, Loc, Tok>
        where Loc: Default, Iter: Iterator<Item = (Loc, Tok)> {
        /// Builds a new adapter from the given iterator.
        ///
        /// This function takes the iterator by-value. If the iterator is not,
        /// `Copy`, it won't be usable anymore after the parsing process. If this
        /// is not desired, one should give to this function a mutable reference
        /// to the iterator instead.
        pub fn new(lex: Iter) -> Self {
            IteratorLexer {
                iter: lex,
                last_pos: Loc::default(),
                marker: ::std::marker::PhantomData
            }
        }
    }
}

// Parser interface.

/// Trait describing a Menhir parser.
///
/// This trait is implemented by the parsers generated by Menhir and describes
/// the parser interface. Menhir should generate a single type implenting this
/// trait for each grammar file.
///
/// The user of the generated parser should probably not use this interface
/// directly and see [`EntryPoint`] instead. This interface should not be
/// considered stable.
///
/// [`EntryPoint`]: trait.EntryPoint.html
pub trait LRParser {
    type Terminal: Copy;
    fn error() -> Self::Terminal;

    type State: Copy;
    type YYType;

    fn default_reduction(state: Self::State)
                         -> Option<SemAct<Self::YYType, Self::State>>;
    fn action(state: Self::State, token: Self::Terminal)
              -> Action<Self::YYType, Self::State>;
}

/// The trait of the entry points of a grammar file.
///
/// This trait describes the main interface of a Menhir parser. Menhir will
/// generate one type implementing this trait for each possible entry point of
/// the grammar file.
pub trait EntryPoint<Parser: LRParser> {
    /// The type of the semantic value produced by a successful parsing.
    type Output;

    /// Extracts the semantic value produced by a succesful parsing from the
    /// resulting stack.
    ///
    /// Calling this function on a stack which is not the result of a successful
    /// parse will most likely panic, but might also return an unspecified but
    /// valid value.
    fn extract_output(stack: Stack<Parser::YYType, Parser::State>) -> Self::Output;

    /// Returns the initial state of the parser automaton for this entry point.
    fn initial() -> Parser::State;

    /// Creates a new parser for this entry point from the given lexer.
    ///
    /// This function is similar to `run` but instead of running the parsing
    /// process, it does nothing and returns a [`ParserState`] instead that
    /// exposes the current state of the parser. However, the interface of
    /// [`ParserState`] should not be considered stable for the moment.
    ///
    /// [`ParserState`]: struct.ParserState.html
    fn new<Lexer>(lex: Lexer)
                  -> Result<ParserState<Lexer, Parser, Self>, Lexer::Error>
        where Lexer: self::Lexer,
              Lexer::Token: Into<(Parser::YYType, Parser::Terminal)>,
              Self: ::std::marker::Sized {
        new::<Lexer, Parser, Self>(lex)
    }

    /// Runs the parsing process for this entry point from the given lexer.
    ///
    /// This requires that the tokens returned by the lexer can be converted
    /// into the `Terminal` type of the parser, which is the internal
    /// representation of tokens. Menhir should have generated an
    /// implementation of `Into` for the good token type.
    ///
    /// If a syntax error is encountered in the input stream, a Menhir parser
    /// will try to recover from it by applying the default strategy which
    /// consists in unwinding the stack until finding a state which accepts a
    /// shift or reduce action on the special `error` token. If the bottom of
    /// the stack is reached, a syntax error is returned. See the relevant
    /// section of the [manual] for more details.
    ///
    /// This function will parse input until one of the following events:
    /// * The parser successfully recognized the start production, in which
    ///   case it will return a value of `Ok(v)`, where `v` is the semantic
    ///   value.
    /// * The parser encountered an unrecoverable error, such as a lexer error
    ///   or a syntax error which it failed to recover from, in which case it
    ///   will return `Err(e)`. See [`Error`] for more details.
    ///
    /// [manual]: http://gallium.inria.fr/~fpottier/menhir/manual.pdf
    /// [`Error`]: enum.Error.html
    fn run<Lexer>(lex: Lexer) -> Result<Self::Output, Error<Lexer, Parser>>
        where Lexer: self::Lexer,
              Lexer::Token: Into<(Parser::YYType, Parser::Terminal)>,
              Lexer::Location: Clone,
              Parser: LRParser,
              Self: ::std::marker::Sized {
        run::<Lexer, Parser, Self>(lex)
    }
}

/// A fatal (non-recoverable parsing error).
///
/// This is the type returned by a Menhir parser upon encountering an error it
/// cannot or failed to recover from.
pub enum Error<Lexer: self::Lexer, Parser: LRParser> {
    /// The parser encountered a syntax error that couldn't be recovered.
    /// See [`SyntaxError`].
    ///
    /// [`SyntaxError`]: struct.SyntaxError.html
    SyntaxError(SyntaxError<Lexer, Parser>),

    /// The lexer returned an error when asked for a token, typically an IO
    /// error or the end of the stream. The carried value depends on the actual
    /// instance of [`Lexer`] being used.
    ///
    /// [`Lexer`]: lexing/trait.Lexer.html
    LexerError(Lexer::Error)
}

/// An unrecoverable syntax error.
///
/// Allows to extract the position in the input stream and the automaton state
/// in which the error was detected.
pub struct SyntaxError<Lexer: self::Lexer, Parser: LRParser> {
    loc: Lexer::Location,
    state: Parser::State
}

/// Extension trait for parser that can provide detailed error messages.
///
/// Menhir will generate an implementation of this trait for the parser type if
/// the grammar file was compiled with the `--compile-errors` option. See the
/// [manual] for information about how to use this feature.
///
/// [manual]: http://gallium.inria.fr/~fpottier/menhir/manual.pdf
pub trait LRErrors: LRParser {
    /// Gives a proper error message to describe the situation in which the
    /// parser entered error-handling mode.
    ///
    /// Returns the message provided by the user for this state in the error
    /// file given to the `--compiler-errors` option.
    fn message(state: Self::State) -> Option<&'static str>;
}

impl<Parser: LRErrors, Lexer: self::Lexer> SyntaxError<Lexer, Parser> {
    /// Returns a propre error message to describe this error, if such a
    /// message was specified.
    ///
    /// This require the parser to implement [`LRErrors`], which is the case
    /// when the grammar is compiled with the `--compile-error` option. See the
    /// [manual] for information about how to use this feature.
    ///
    /// [`LRErrors`]: trait.LRErrors.html
    /// [manual]: http://gallium.inria.fr/~fpottier/menhir/manual.pdf
    pub fn as_str(&self) -> Option<&'static str> {
        Parser::message(self.state)
    }
}

impl<Parser: LRParser, Lexer: self::Lexer> SyntaxError<Lexer, Parser> {
    /// Returns the location in the input stream of the token where the error
    /// was detected.
    ///
    /// The actual type of this value depends on the instance of [`Lexer`] being
    /// used.
    ///
    /// [`Lexer`]: lexing/trait.Lexer.html
    pub fn location(&self) -> &Lexer::Location {
        &self.loc
    }
}

// Incremental interface.

/// The result of various parsing operations.
/// 
/// This type should not be considered stable.
enum ParseResult<Output, Error, Fatal> {
    Success(Output),
    Error(Error),
    Fatal(Fatal)
}

/// The state of the parser during the parsing process.
///
/// The interface of this type should not be considered stable.
/// In the future, this type will be used to expose the incremental interface,
/// which allows to run the parsing process step-by-step and access its
/// internals
pub struct ParserState<Lexer, Parser, Entry>
    where Parser: LRParser,
          Lexer: self::Lexer,
          Entry: EntryPoint<Parser> {
    state: Parser::State,
    yylval: Parser::YYType,
    stack: Stack<Parser::YYType, Parser::State>,
    lookahead: Parser::Terminal,
    location: Lexer::Location,
    lexer: Lexer,
    entry: ::std::marker::PhantomData<Entry>
}

// Runs a single step of the parsing process.
// Contains the actual logic of the LR loop.
impl<Lexer, Parser, Entry> ParserState<Lexer, Parser, Entry>
    where Parser: LRParser,
          Lexer: self::Lexer,
          Lexer:: Token: Into<(Parser::YYType, Parser::Terminal)>,
          Entry: EntryPoint<Parser> {
    fn step(self) -> ParseResult<Entry::Output,
                                     ErrorState<Lexer, Parser, Entry>,
                                     Error<Lexer, Parser>> {
        let ParserState {
            mut state, mut yylval, mut stack,
            mut lookahead, mut location, mut lexer,
            entry: _
        } = self;

        'a: loop {
            match Parser::action(state, lookahead) {
                Action::Shift(shift) => {
                    stack.push((state, yylval));
                    state = shift;

                    while let Some(red) = Parser::default_reduction(state) {
                        match red {
                            Some(code) => state = code(state, &mut stack),
                            None => break 'a
                        }
                    }

                    // discard
                    let (pos, (nval, tok)) = match lexer.input() {
                        Ok((pos, tok)) => (pos, tok.into()),
                        Err(err) =>
                            return ParseResult::Fatal(Error::LexerError(err))
                    };
                    lookahead = tok;
                    location = pos;
                    yylval = nval;
                }

                Action::Reduce(Some(reduce)) => {
                    state = reduce(state, &mut stack);
                    while let Some(red) = Parser::default_reduction(state) {
                        match red {
                            Some(code) => state = code(state, &mut stack),
                            None => break 'a
                        }
                    }
                }

                Action::Reduce(None) => break,
                Action::Err => {
                    return ParseResult::Error(ErrorState {
                        state: ParserState {
                            state: state, yylval: yylval, stack: stack,
                            lookahead: lookahead, location: location, lexer: lexer,
                            entry: ::std::marker::PhantomData
                        }
                    });
                }
            }
        }

        ParseResult::Success(Entry::extract_output(stack))
    }
}

// Implements the monolithic interface in terms of the incremental interface,
// with the default error handling strategy.
impl<Lexer, Parser, Entry> ParserState<Lexer, Parser, Entry>
    where Parser: LRParser,
          Lexer: self::Lexer,
          Lexer::Token: Into<(Parser::YYType, Parser::Terminal)>,
          Lexer::Location: Clone,
          Entry: EntryPoint<Parser> {
    fn run(mut self) -> Result<Entry::Output, Error<Lexer, Parser>> {
        loop {
            match self.step() {
                ParseResult::Success(out) => return Ok(out),

                ParseResult::Error(mut err_state) => {
                    let loc = err_state.state.location.clone();
                    let state = err_state.state.state;

                    loop {
                        match err_state.try_recover() {
                            ParseResult::Success(ok_state) => {
                                self = ok_state;
                                break;
                            }

                            ParseResult::Fatal(()) =>
                                return Err(Error::SyntaxError(
                                    SyntaxError { loc: loc, state: state }
                                )),

                            ParseResult::Error(new_err_state) =>
                                err_state = new_err_state
                        }
                    }
                }

                ParseResult::Fatal(err) => return Err(err)
            }
        }
    }
}

// Incremental interface: error handling.

// The state of the parser after a recoverable error.
struct ErrorState<Lexer, Parser, Entry>
    where Parser: LRParser,
          Lexer: self::Lexer,
          Entry: EntryPoint<Parser> {
    state: ParserState<Lexer, Parser, Entry>
}

// The result of an error recovery operation.
type RecoveryResult<Lexer, Parser, Entry> =
    ParseResult<ParserState<Lexer, Parser, Entry>,
                ErrorState<Lexer, Parser, Entry>,
                ()>;

impl<Parser, Lexer, Entry> ErrorState<Lexer, Parser, Entry>
    where Parser: LRParser,
          Lexer: self::Lexer,
          Lexer::Location: Clone,
          Entry: EntryPoint<Parser> {
    fn try_recover(mut self) -> RecoveryResult<Lexer, Parser, Entry> {
        if let Action::Err = Parser::action(self.state.state, Parser::error()) {
            return match self.state.stack.pop() {
                Some((state, _)) => {
                    self.state.state = state;
                    ParseResult::Error(self)
                }

                None => ParseResult::Fatal(())
            }
        }

        ParseResult::Success(ParserState {
            lookahead: Parser::error(),
            .. self.state
        })
    }
}

// Convenience functions for implementing LRParser::new() and LRParser::run().

// Creates a new parser from the given lexer.
// FIXME: Should not consume any input.
fn new<Lexer, Parser, Entry>(mut lex: Lexer)
                                 -> Result<ParserState<Lexer, Parser, Entry>,
                                           Lexer::Error>
    where Lexer: self::Lexer,
          Lexer::Token: Into<(Parser::YYType, Parser::Terminal)>,
          Parser: LRParser,
          Entry: EntryPoint<Parser> {
    let state = Entry::initial();
    let stack = Vec::new();
    let (pos, tok) = try!(lex.input());
    let (yylval, tok) = tok.into();
    Ok(ParserState {
        state: state, stack: stack, yylval: yylval,
        lookahead: tok, location: pos, lexer: lex,
        entry: ::std::marker::PhantomData
    })
}

// Implements the monolithic interface in terms of the incremental interface.
// Creates a new parser and run it, with the default error handling strategy.
fn run<Lexer, Parser, Entry>(lex: Lexer) -> Result<Entry::Output,
                                                   Error<Lexer, Parser>>
    where Lexer: self::Lexer,
          Lexer::Token: Into<(Parser::YYType, Parser::Terminal)>,
          Lexer::Location: Clone,
          Parser: LRParser,
          Entry: EntryPoint<Parser> {
    let state = match new::<_, _, Entry>(lex) {
        Ok(state) => state,
        Err(err) => return Err(Error::LexerError(err))
    };
    state.run()
}
